{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case Study 1 : Collecting Data from Twitter\n",
    "\n",
    "Due Date: 2/8/2021, **BEFORE the beginning of class at 11:00am**\n",
    "\n",
    "## **NOTE: There are *always* last minute issues submitting the case studies.  DO NOT WAIT UNTIL THE LAST MINUTE!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://upload.wikimedia.org/wikipedia/en/thumb/9/9f/Twitter_bird_logo_2012.svg/220px-Twitter_bird_logo_2012.svg.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TEAM Members:** Please EDIT this cell and add the names of all the team members in your team\n",
    "\n",
    "    Kate Sincaglia\n",
    "    \n",
    "    Mitchell Sirois\n",
    "    \n",
    "    Bryson Tang\n",
    "\n",
    "    Jyalu Wu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Suggested Readings:** \n",
    "* Chapter 1 and Chapter 9 of the book \"Mining the Social Web\" can help a lot if you get stuck. \n",
    "* In fact, it is intentional that many of these questions can be answered directly from there (except for question 4)!\n",
    "* The idea is to ease you into the case studies :-)\n",
    "\n",
    "**Don't forget!**\n",
    "* You will need to install the python-twitter library to access the Twitter API\n",
    " * pip install twitter\n",
    "\n",
    "\n",
    "** NOTE **\n",
    "* **Please don't forget to save the notebook frequently when working in IPython Notebook, otherwise the changes you made can be lost**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1 (20 points): Sampling Twitter Data with either Search or Streaming API about a certain topic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Select a topic that you are interested in, for example, \"WPI\" or \"Lady Gaga\"\n",
    "* Use Twitter API to sample a collection of tweets about this topic. (It would be recommended that the number of tweets should be larger than 200, but smaller than 1 million.\n",
    "* Store the tweets you downloaded into a local file (txt file or json file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import twitter\n",
    "import json\n",
    "from collections import Counter\n",
    "from prettytable import PrettyTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Length of statuses 100\n",
      "Length of statuses 200\n",
      "Length of statuses 300\n",
      "Length of statuses 400\n",
      "Length of statuses 500\n",
      "{\n",
      " \"created_at\": \"Sun Feb 07 03:48:32 +0000 2021\",\n",
      " \"id\": 1358261337105829888,\n",
      " \"id_str\": \"1358261337105829888\",\n",
      " \"text\": \"MACHINE OUTAGE: An elevator servicing Street To Mezzanine @ Court Sq (NE corner of Jackson Avenue and 23rd Street) is out of service.\",\n",
      " \"truncated\": false,\n",
      " \"entities\": {\n",
      "  \"hashtags\": [],\n",
      "  \"symbols\": [],\n",
      "  \"user_mentions\": [],\n",
      "  \"urls\": []\n",
      " },\n",
      " \"metadata\": {\n",
      "  \"iso_language_code\": \"en\",\n",
      "  \"result_type\": \"recent\"\n",
      " },\n",
      " \"source\": \"<a href=\\\"http://www.nycaccessible.com\\\" rel=\\\"nofollow\\\">NYC Accessible</a>\",\n",
      " \"in_reply_to_status_id\": null,\n",
      " \"in_reply_to_status_id_str\": null,\n",
      " \"in_reply_to_user_id\": null,\n",
      " \"in_reply_to_user_id_str\": null,\n",
      " \"in_reply_to_screen_name\": null,\n",
      " \"user\": {\n",
      "  \"id\": 2994876652,\n",
      "  \"id_str\": \"2994876652\",\n",
      "  \"name\": \"nycaccessible\",\n",
      "  \"screen_name\": \"nycoutages\",\n",
      "  \"location\": \"New York City\",\n",
      "  \"description\": \"Elevator and Escalator status updates for the NYC Subway system\",\n",
      "  \"url\": \"http://t.co/oeLUPzJ9Og\",\n",
      "  \"entities\": {\n",
      "   \"url\": {\n",
      "    \"urls\": [\n",
      "     {\n",
      "      \"url\": \"http://t.co/oeLUPzJ9Og\",\n",
      "      \"expanded_url\": \"http://www.nycaccessible.com\",\n",
      "      \"display_url\": \"nycaccessible.com\",\n",
      "      \"indices\": [\n",
      "       0,\n",
      "       22\n",
      "      ]\n",
      "     }\n",
      "    ]\n",
      "   },\n",
      "   \"description\": {\n",
      "    \"urls\": []\n",
      "   }\n",
      "  },\n",
      "  \"protected\": false,\n",
      "  \"followers_count\": 96,\n",
      "  \"friends_count\": 42,\n",
      "  \"listed_count\": 4,\n",
      "  \"created_at\": \"Fri Jan 23 21:28:39 +0000 2015\",\n",
      "  \"favourites_count\": 15,\n",
      "  \"utc_offset\": null,\n",
      "  \"time_zone\": null,\n",
      "  \"geo_enabled\": false,\n",
      "  \"verified\": false,\n",
      "  \"statuses_count\": 327131,\n",
      "  \"lang\": null,\n",
      "  \"contributors_enabled\": false,\n",
      "  \"is_translator\": false,\n",
      "  \"is_translation_enabled\": false,\n",
      "  \"profile_background_color\": \"022330\",\n",
      "  \"profile_background_image_url\": \"http://abs.twimg.com/images/themes/theme15/bg.png\",\n",
      "  \"profile_background_image_url_https\": \"https://abs.twimg.com/images/themes/theme15/bg.png\",\n",
      "  \"profile_background_tile\": false,\n",
      "  \"profile_image_url\": \"http://pbs.twimg.com/profile_images/560627508215693312/s_n6wUw6_normal.png\",\n",
      "  \"profile_image_url_https\": \"https://pbs.twimg.com/profile_images/560627508215693312/s_n6wUw6_normal.png\",\n",
      "  \"profile_banner_url\": \"https://pbs.twimg.com/profile_banners/2994876652/1422500001\",\n",
      "  \"profile_link_color\": \"0084B4\",\n",
      "  \"profile_sidebar_border_color\": \"A8C7F7\",\n",
      "  \"profile_sidebar_fill_color\": \"C0DFEC\",\n",
      "  \"profile_text_color\": \"333333\",\n",
      "  \"profile_use_background_image\": true,\n",
      "  \"has_extended_profile\": false,\n",
      "  \"default_profile\": false,\n",
      "  \"default_profile_image\": false,\n",
      "  \"following\": false,\n",
      "  \"follow_request_sent\": false,\n",
      "  \"notifications\": false,\n",
      "  \"translator_type\": \"none\"\n",
      " },\n",
      " \"geo\": null,\n",
      " \"coordinates\": null,\n",
      " \"place\": null,\n",
      " \"contributors\": null,\n",
      " \"is_quote_status\": false,\n",
      " \"retweet_count\": 0,\n",
      " \"favorite_count\": 0,\n",
      " \"favorited\": false,\n",
      " \"retweeted\": false,\n",
      " \"lang\": \"en\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "#---------------------------------------------\n",
    "# Define a Function to Login Twitter API\n",
    "def oauth_login():\n",
    "    # Prof. Paffenroth has a developer account for the class.  He will provide the Twitter access tokens for\n",
    "    # each team\n",
    "    # See https://developer.twitter.com/docs/auth/oauth for more information \n",
    "    # on Twitter's OAuth implementation.\n",
    "    \n",
    "    CONSUMER_KEY = 'oVek8jmhI4sz8SbKnT1e6UsIh'\n",
    "    CONSUMER_SECRET ='3eGB6ip82K3XowIDEmz9JXIbRc2uFSlHvjPJ8Lmkf3HVIdlmhM'\n",
    "    OAUTH_TOKEN = '571213367-H0r2WfySE7L4vgUJHv4YLW2vZGLa7TEPP7iWsTNu'\n",
    "    OAUTH_TOKEN_SECRET = 'uKcYixkDRaCUvaP2oqH9a9fIaIB9nf4NKz32iqo2t7B7K'\n",
    "\n",
    "    \n",
    "    auth = twitter.oauth.OAuth(OAUTH_TOKEN, OAUTH_TOKEN_SECRET,\n",
    "                               CONSUMER_KEY, CONSUMER_SECRET)\n",
    "    \n",
    "    twitter_api = twitter.Twitter(auth=auth)\n",
    "    return twitter_api\n",
    "\n",
    "twitter_api = oauth_login()\n",
    "\n",
    "#----------------------------------------------\n",
    "# Your code starts here\n",
    "#   Please add comments or text cells in between to explain the general idea of each block of the code.\n",
    "#   Please feel free to add more cells below this cell if necessary\n",
    "\n",
    "q = 'outage'\n",
    "\n",
    "count = 100\n",
    "\n",
    "# Import unquote to prevent URL encoding errors in next_results\n",
    "from urllib.parse import unquote\n",
    "\n",
    "search_results = twitter_api.search.tweets(q=q, count=count)\n",
    "\n",
    "statuses = search_results['statuses']\n",
    "\n",
    "for _ in range(5): #takes count 5 times, 100*5 = 500\n",
    "    print('Length of statuses', len(statuses))\n",
    "    try:\n",
    "        next_results = search_results['search_metadata']['next_results']\n",
    "    except KeyError as e: # No more results when next_results doesn't exist\n",
    "        break\n",
    "\n",
    "    # Create a dictionary from next_results, which has the following form:\n",
    "    kwargs = dict([ kv.split('=') for kv in unquote(next_results[1:]).split(\"&\") ])\n",
    "\n",
    "    search_results = twitter_api.search.tweets(**kwargs)\n",
    "    statuses += search_results['statuses']\n",
    "\n",
    "# Show one sample search result by slicing the list...\n",
    "print(json.dumps(statuses[0], indent=1)) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report some statistics about the tweets you collected \n",
    "\n",
    "* The topic of interest: < INSERT YOUR TOPIC HERE>\n",
    "\n",
    "\n",
    "* The total number of tweets collected:  < INSERT THE NUMBER HERE>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*-----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2 (20 points): Analyzing Tweets and Tweet Entities with Frequency Analysis\n",
    "\n",
    "**1. Word Count:** \n",
    "* Use the tweets you collected in Problem 1, and compute the frequencies of the words being used in these tweets. \n",
    "* Plot a table of the top 30 words with their counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+-----------------------+\n|      Top 30 Words     |\n+---------------+-------+\n|      Word     | Count |\n+---------------+-------+\n|     outage    |  421  |\n|      the      |  296  |\n|       to      |  294  |\n|       a       |  269  |\n|       in      |  211  |\n|     power     |  210  |\n|      for      |  163  |\n|       is      |  156  |\n|       rt      |  154  |\n|      and      |  145  |\n|       an      |  137  |\n|      are      |  102  |\n|       of      |   98  |\n|       we      |   96  |\n|       i       |   87  |\n|       be      |   85  |\n|       on      |   71  |\n|       at      |   69  |\n| @citypowerjhb |   67  |\n|      you      |   66  |\n|    internet   |   64  |\n|      this     |   63  |\n|       my      |   57  |\n|       it      |   54  |\n|      have     |   50  |\n|      has      |   48  |\n|     there     |   48  |\n|      your     |   47  |\n|      been     |   46  |\n|      out      |   45  |\n+---------------+-------+\n"
     ]
    }
   ],
   "source": [
    "import cloudpickle\n",
    "import nltk\n",
    "# import matplotlib.pyplot as plt\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "# pickling/saving data\n",
    "f = open('outages.pickle', 'wb')\n",
    "cloudpickle.dump(statuses, f)\n",
    "f.close()\n",
    "\n",
    "# getting only the words in the tweets, clean them\n",
    "words = []\n",
    "result_set = set()\n",
    "\n",
    "for tweet in statuses:\n",
    "    text = tweet['text']\n",
    "    text = text.lower()\n",
    "    dirty_words = [ w for w in text.split() ]\n",
    "    dirty_words = [word.strip('.,!;()[]:') for word in dirty_words]\n",
    "    dirty_words = [word.replace(\"'s\", '') for word in dirty_words]\n",
    "    words += dirty_words\n",
    "\n",
    "# frequency distribution\n",
    "freq_dist = nltk.FreqDist(words)\n",
    "\n",
    "# top 30 words\n",
    "top30 = freq_dist.most_common(30)\n",
    "\n",
    "# table of top 30 words\n",
    "x = PrettyTable()\n",
    "x.title = 'Top 30 Words'\n",
    "x.field_names = ['Word', 'Count']\n",
    "x.add_rows(top30)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Find the most popular tweets in your collection of tweets**\n",
    "\n",
    "Please plot a table of the top 10 tweets that are the most popular among your collection, i.e., the tweets with the largest number of retweet counts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Given a list of tweet objects, returns a list of unique tuples that contain, for each tweet:\n",
    "    1. The text in the tweet\n",
    "    2. The number of retweets for the tweet\n",
    "\"\"\"\n",
    "def get_tweets_rt_count(data):\n",
    "    tweets = []\n",
    "    rt_counts = []\n",
    "\n",
    "    for tweet in data:\n",
    "        tweets.append(tweet['text'])\n",
    "        rt_counts.append(tweet['retweet_count'])\n",
    "\n",
    "    return list(set(zip(tweets, rt_counts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Returns the second item in a tuple containing the text of a tweet and the number of retweets for the tweet.\n",
    "\"\"\"\n",
    "def rt_count(text_rt_tuple):\n",
    "    return tup[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "('We are aware of an outage at Lotus 88/11kV SS. Start time 23:09. https://t.co/Qfbt2xQIlB', 0)\n+--------------------------------------------------------------------+\n|                     Top 10 Most Popular Tweets                     |\n+----------------------------------------------------+---------------+\n|                       Tweet                        | Retweet Count |\n+----------------------------------------------------+---------------+\n|   RT @JFriks: So what movie got stocked in while   |      333      |\n|  there was power outage? https://t.co/N8nIEmIRWo   |               |\n+----------------------------------------------------+---------------+\n| RT @Abramjee: Police are looking for these two men |      272      |\n| who pretended to be @CityPowerJhb employees. They  |               |\n|       went to a substation chamber in Selby‚Ä¶       |               |\n+----------------------------------------------------+---------------+\n| RT @PARInetwork: Today when #4G services have been |      100      |\n|  restored in Jammu and Kashmir, here's a look at   |               |\n|     how the internet outage affected the peo‚Ä¶      |               |\n+----------------------------------------------------+---------------+\n|    RT @weiwuxiansnose: \"Outage\" by SugarMilkTea    |       85      |\n|                                                    |               |\n|   üîå what do you get when you mix one (1) horny    |               |\n| bastard and one (1) city boy who's never experie‚Ä¶  |               |\n+----------------------------------------------------+---------------+\n| RT @DougMadory: Internet in Myanmar has gone down  |       73      |\n|  a 2nd time in 6 days. This time far more severe   |               |\n|                     than last.                     |               |\n|                                                    |               |\n|           Previous outage was focused o‚Ä¶           |               |\n+----------------------------------------------------+---------------+\n|         RT @ReadyNJ: Winter Weather Update         |       40      |\n|    ‚ùÑÔ∏èFollow @NWS_MountHolly &amp; @NWSNewYorkNY     |               |\n|          ‚ùÑÔ∏èTraffice updates @NewJerseyDOT           |               |\n|              https://t.co/Z29sBX8YGa               |               |\n|                        ‚ùÑÔ∏èCh‚Ä¶                        |               |\n+----------------------------------------------------+---------------+\n|   RT @opg: After a record breaking 3 year run of   |       28      |\n|   generating clean carbon-free power, Unit 1 at    |               |\n|  Darlington Nuclear is taking a well-deserved m‚Ä¶   |               |\n+----------------------------------------------------+---------------+\n|   RT @EAFIFAMOBILE: Active listings will not be    |       16      |\n|  cancelled or delayed during the outage. Listings  |               |\n|   that were set to expire during the outage wi‚Ä¶    |               |\n+----------------------------------------------------+---------------+\n|  RT @OpenObservatory: Today Myanmar appears to be  |       15      |\n| experiencing an internet outage, as shown through  |               |\n|            several public data sources:            |               |\n|                                                    |               |\n|                    ‚Ä¢ @caida_i‚Ä¶                     |               |\n+----------------------------------------------------+---------------+\n|  RT @NAofSFM: Use flashlights, not candles if you  |       12      |\n| have a power outage. #CandleSafety #FirePrevention |               |\n|      #FireSafetyTips https://t.co/C35IWEAI32       |               |\n+----------------------------------------------------+---------------+\n"
     ]
    }
   ],
   "source": [
    "from tables import *\n",
    "import numpy as np\n",
    "\n",
    "# retrieve data/unpickle\n",
    "pickle_off = open(\"outages.pickle\",\"rb\")\n",
    "outages = cloudpickle.load(pickle_off)\n",
    "\n",
    "# get only the tweets and retweet count\n",
    "tweets_rts = get_tweets_rt_count(outages)\n",
    "print(tweets_rts[0])\n",
    "\n",
    "# sort by retweet count\n",
    "tweets_rts.sort(reverse=True,key=rt_count)\n",
    "\n",
    "# top 10 table\n",
    "top10 = tweets_rts[:10]\n",
    "\n",
    "x = PrettyTable()\n",
    "x.title = 'Top 10 Most Popular Tweets'\n",
    "x.field_names = ['Tweet', 'Retweet Count']\n",
    "x.add_rows(top10)\n",
    "x._max_width = {\"Tweet\" : 50, \"Retweet Count\" : 25}\n",
    "x.hrules = 1\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Find the most popular Tweet Entities in your collection of tweets**\n",
    "\n",
    "Please plot a table of the top 10 hashtags, top 10 user mentions that are the most popular in your collection of tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('WellingtonOPP', 9), ('WellingtonCounty', 8), ('Outage', 6), ('Guelph', 6), ('cryptocurrency', 4), ('Mets', 4), ('BREAKING', 3), ('JoburgUpdates', 2), ('StoneyCreek', 2), ('poweroutage', 2)]\n",
      "\n",
      "[('JustRyCole', 48), ('CityPowerJhb', 48), ('BauerOutage', 11), ('PHEDconnect', 9), ('OPP_WR', 8), ('opg', 8), ('PSLToFlushing', 7), ('virginmedia', 6), ('GuelphHydro', 6), ('SkyHelpTeam', 6)]\n",
      "\n",
      "+------------------+-------+\n",
      "| Hashtags         | Count |\n",
      "+------------------+-------+\n",
      "| WellingtonOPP    |     9 |\n",
      "| WellingtonCounty |     8 |\n",
      "| Outage           |     6 |\n",
      "| Guelph           |     6 |\n",
      "| cryptocurrency   |     4 |\n",
      "| Mets             |     4 |\n",
      "| BREAKING         |     3 |\n",
      "| JoburgUpdates    |     2 |\n",
      "| StoneyCreek      |     2 |\n",
      "| poweroutage      |     2 |\n",
      "+------------------+-------+\n",
      "+-----------------+-------+\n",
      "| Mentioned Users | Count |\n",
      "+-----------------+-------+\n",
      "| JustRyCole      |    48 |\n",
      "| CityPowerJhb    |    48 |\n",
      "| BauerOutage     |    11 |\n",
      "| PHEDconnect     |     9 |\n",
      "| OPP_WR          |     8 |\n",
      "| opg             |     8 |\n",
      "| PSLToFlushing   |     7 |\n",
      "| virginmedia     |     6 |\n",
      "| GuelphHydro     |     6 |\n",
      "| SkyHelpTeam     |     6 |\n",
      "+-----------------+-------+\n"
     ]
    }
   ],
   "source": [
    "#----------------------------------------------\n",
    "# Your code starts here\n",
    "#   Please add comments or text cells in between to explain the general idea of each block of the code.\n",
    "#   Please feel free to add more cells below this cell if necessary\n",
    "#Katie/Bryson\n",
    "\n",
    "#gather up all of the mentioned users and hashtags\n",
    "\n",
    "hashtags = [ hashtag['text']\n",
    "             for status in statuses\n",
    "                 for hashtag in status['entities']['hashtags'] ]\n",
    "\n",
    "mentioned_user = [user_mention['screen_name']\n",
    "                 for status in statuses\n",
    "                     for user_mention in status['entities']['user_mentions']] #this collects all user mentions\n",
    "\n",
    "#count how many times each hashtag is used and user is mentioned\n",
    "\n",
    "for item in [hashtags, mentioned_user]:\n",
    "    c = Counter(item)\n",
    "    print(c.most_common()[:10]) # top 10\n",
    "    print()\n",
    "    \n",
    "#format the data into a pretty table\n",
    "\n",
    "for label, data in (('Hashtags', hashtags),\n",
    "                    ('Mentioned Users', mentioned_user)):\n",
    "    pt = PrettyTable(field_names=[label, 'Count'])\n",
    "    c = Counter(data)\n",
    "    [ pt.add_row(kv) for kv in c.most_common()[:10] ]\n",
    "    pt.align[label], pt.align['Count'] = 'l', 'r' # Set column alignment\n",
    "    print(pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3 (20 points): Getting \"All\" friends and \"All\" followers of a popular user in twitter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* choose a popular twitter user who has many followers, such as \"ladygaga\".\n",
    "* Get the list of all friends and all followers of the twitter user.\n",
    "* Plot 20 out of the followers, plot their ID numbers and screen names in a table.\n",
    "* Plot 20 out of the friends (if the user has more than 20 friends), plot their ID numbers and screen names in a table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------\n",
    "# Your code starts here\n",
    "#   Please add comments or text cells in between to explain the general idea of each block of the code.\n",
    "#   Please feel free to add more cells below this cell if necessary\n",
    "\n",
    "import time\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "# Get followers\n",
    "friend_cursor = -1\n",
    "follower_cursor = -1\n",
    "\n",
    "user = \"TweetWorcester\"\n",
    "\n",
    "number_of_users_to_collect = 300\n",
    "\n",
    "searches = 0\n",
    "\n",
    "followers = []\n",
    "friends = []\n",
    "while friend_cursor != 0 and follower_cursor != 0 and number_of_users_to_collect != 0:\n",
    "    try:\n",
    "        count = 200\n",
    "        if number_of_users_to_collect < 200:\n",
    "            count = number_of_users_to_collect\n",
    "        \n",
    "        if follower_cursor != 0:\n",
    "            res_follower = twitter_api.followers.list(screen_name=user, \n",
    "                                                      cursor=follower_cursor, \n",
    "                                                      count=count)\n",
    "            \n",
    "            followers += [{\"screen_name\": u[\"screen_name\"], \"id\": u[\"id\"]} for u in res_follower['users']]\n",
    "            follower_cursor = res_follower[\"next_cursor\"]\n",
    "                        \n",
    "        if friend_cursor != 0:            \n",
    "            res_friends = twitter_api.friends.list(screen_name=user, \n",
    "                                                   ursor=friend_cursor, \n",
    "                                                   count=count)\n",
    "            \n",
    "            friends += [{\"screen_name\": u[\"screen_name\"], \"id\": u[\"id\"]}for u in res_friends['users']]\n",
    "            friend_cursor = res_friends[\"next_cursor\"]\n",
    "        \n",
    "        searches += 1\n",
    "        number_of_users_to_collect -= count\n",
    "    except twitter.api.TwitterHTTPError:\n",
    "        print(\"Waiting...\")\n",
    "        rates = twitter_api.application.rate_limit_status()\n",
    "        \n",
    "        time_left = rates[\"resources\"][\"followers\"][\"/followers/list\"][\"reset\"] - time.time()\n",
    "        \n",
    "        time.sleep(time_left + 2)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_user_table(data, title, length=20):\n",
    "    table = PrettyTable([\"Screen Name\", \"Id\"])\n",
    "    table.title = title\n",
    "    \n",
    "    if len(data) < length:\n",
    "        length = len(data)\n",
    "        \n",
    "    for i in range(length):\n",
    "        row = data[i]\n",
    "        table.add_row([row[\"screen_name\"], row[\"id\"]])\n",
    "    \n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1612548034.287955"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------+\n",
      "|                Friends                |\n",
      "+-----------------+---------------------+\n",
      "|   Screen Name   |          Id         |\n",
      "+-----------------+---------------------+\n",
      "|     tedlieu     |       21059255      |\n",
      "|      wsbmod     | 1282418324228337665 |\n",
      "|  OldMemeArchive | 1349856571988258826 |\n",
      "|      POTUS      | 1349149096909668363 |\n",
      "|    nookipedia   |      213478688      |\n",
      "|     Pokemon     |       96879107      |\n",
      "|   staceyabrams  |      216065430      |\n",
      "|     jschlatt    |      4694011844     |\n",
      "| ProgressBar202_ |      4685749051     |\n",
      "|  LeftAccidental | 1303873858936737793 |\n",
      "|   mcblockdaily  | 1324477660182007810 |\n",
      "|   StrangestMp4  | 1194413925569159169 |\n",
      "|  CallMeCarsonYT |      2349536690     |\n",
      "|  MoistCr1TiKaL  |      559229566      |\n",
      "|    jacksfilms   |       9989862       |\n",
      "|    robber0540   |      3086280070     |\n",
      "|   hasanthehun   |      326756275      |\n",
      "|   KamalaHarris  |       30354991      |\n",
      "|     JoeBiden    |        939091       |\n",
      "|    hankgreen    |       61592079      |\n",
      "+-----------------+---------------------+\n",
      "+------------------------------+\n",
      "|          Followers           |\n",
      "+-----------------+------------+\n",
      "|   Screen Name   |     Id     |\n",
      "+-----------------+------------+\n",
      "|  ashleybaldw1n  | 3133724330 |\n",
      "|  srastevensb201 | 885519948  |\n",
      "|  ABIGAILOKYERE9 | 3432529809 |\n",
      "|   CKennedy046   | 1541884219 |\n",
      "|   Alexfang1023  | 2233688410 |\n",
      "|     ralphpig    | 860254500  |\n",
      "|   Andrew02445   | 1457343038 |\n",
      "| screamingdonuts | 1319192641 |\n",
      "|     tang_meg    |  11726682  |\n",
      "|     mmbtang     |  11699752  |\n",
      "+-----------------+------------+\n"
     ]
    }
   ],
   "source": [
    "from prettytable import PrettyTable\n",
    "\n",
    "friends_table  = generate_user_table(friends, \"Friends\")\n",
    "followers_table  = generate_user_table(followers, \"Followers\")\n",
    "\n",
    "print(friends_table)\n",
    "print(followers_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Compute the mutual friends within the two groups, i.e., the users who are in both friend list and follower list, plot their ID numbers and screen names in a table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------+\n",
      "|            Mutual           |\n",
      "+----------------+------------+\n",
      "|  Screen Name   |     Id     |\n",
      "+----------------+------------+\n",
      "| ashleybaldw1n  | 3133724330 |\n",
      "| srastevensb201 | 885519948  |\n",
      "|    ralphpig    | 860254500  |\n",
      "|    tang_meg    |  11726682  |\n",
      "|    mmbtang     |  11699752  |\n",
      "+----------------+------------+\n"
     ]
    }
   ],
   "source": [
    "#----------------------------------------------\n",
    "# Your code starts here\n",
    "#   Please add comments or text cells in between to explain the general idea of each block of the code.\n",
    "#   Please feel free to add more cells below this cell if necessary\n",
    "\n",
    "mutual = []\n",
    "for u in followers:\n",
    "    for r in friends:\n",
    "        if u['id'] == r[\"id\"]:\n",
    "            mutual.append(u)\n",
    "            \n",
    "mutual_table  = generate_user_table(mutual, \"Mutual\")\n",
    "\n",
    "print(mutual_table)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*------------------------\n",
    "\n",
    "# Problem 4 (20 points): Business question \n",
    "\n",
    "Run some additional experiments with your data to gain familiarity with the twitter data and twitter API.\n",
    "\n",
    "* Come up with a business question that Twitter data could help answer.\n",
    "* Decribe the business case.\n",
    "* How could Twitter data help a company decide how to spend its resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------\n",
    "# Your code starts here\n",
    "#   Please add comments or text cells in between to explain the general idea of each block of the code.\n",
    "#   Please feel free to add more cells below this cell if necessary\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "q = 'snow AND outage'\n",
    "#q = \"andrew\"\n",
    "# lat = \"42.2743\"\n",
    "# long = \"-71.8081\"\n",
    "# rad = \"50mi\"\n",
    "# geocode = lat + \",\" + long + \",\" + rad\n",
    "\n",
    "# remaining_searches = rates[\"resources\"][\"search\"][\"/search/tweets\"][\"remaining\"]\n",
    "remaining_searches = 5\n",
    "count = 1000\n",
    "statuses = []\n",
    "# See https://dev.twitter.com/docs/api/1.1/get/search/tweets\n",
    "for i in range(remaining_searches):\n",
    "    search_results = twitter_api.search.tweets(q=q, count=count)\n",
    "\n",
    "    statuses += search_results['statuses']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "outages = {}\n",
    "for i in range(len(statuses)):\n",
    "    if statuses[i][\"user\"][\"location\"]:\n",
    "        if statuses[i][\"user\"][\"location\"] in outages:\n",
    "            outages[statuses[i][\"user\"][\"location\"]] += 1\n",
    "        else:\n",
    "            outages[statuses[i][\"user\"][\"location\"]] = 1\n",
    "            \n",
    "# data = list(outages.items())\n",
    "# an_array = np.array(data)\n",
    "df = pd.DataFrame(list(outages.items()), columns=[\"Location\", \"Count\"]).sort_values(by=\"Count\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Location</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Brooklyn, NY</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NJ</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Kurdistan, Europe</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>New York, NY</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Pittsburgh</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>New Jersey, USA</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>read pinned byf!</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>the Shore, NJ, Philly, NYC</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Location  Count\n",
       "7                  Chicago, IL     20\n",
       "18                Brooklyn, NY     15\n",
       "10                          NJ     10\n",
       "38           Kurdistan, Europe     10\n",
       "43                New York, NY     10\n",
       "..                         ...    ...\n",
       "30                  Pittsburgh      5\n",
       "31                 Seattle, WA      5\n",
       "32             New Jersey, USA      5\n",
       "33            read pinned byf!      5\n",
       "67  the Shore, NJ, Philly, NYC      5\n",
       "\n",
       "[68 rows x 2 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "305.78343391418457"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*-----------------\n",
    "# Done\n",
    "\n",
    "All set! \n",
    "\n",
    "** What do you need to submit?**\n",
    "\n",
    "* **Notebook File**: Save this IPython notebook, and find the notebook file in your folder (for example, \"filename.ipynb\"). This is the file you need to submit. Please make sure all the plotted tables and figures are in the notebook. If you used \"ipython notebook --pylab=inline\" to open the notebook, all the figures and tables should have shown up in the notebook.\n",
    "\n",
    "\n",
    "* **PPT Slides**: please prepare PPT slides (for 15 minutes' talk) to present about the case study . We will ask two teams which are randomly selected to present their case studies in class for this case study. \n",
    "\n",
    "Please compress all the files in a zipped file.\n",
    "\n",
    "\n",
    "** How to submit: **\n",
    "\n",
    "        Please submit through email to Prof. Paffenroth (rcpaffenroth@wpi.edu).\n",
    "\n",
    "#### We auto-process the submissions so make sure your subject line is *exactly*:\n",
    "\n",
    "### DS3010 Case Study 1 Team ??\n",
    "\n",
    "#### where ?? is your team number.\n",
    "        \n",
    "** Note: Each team just needs to submits one submission **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grading Criteria:\n",
    "\n",
    "**Totoal Points: 100**\n",
    "\n",
    "\n",
    "---------------------------------------------------------------------------\n",
    "**Notebook results:**\n",
    "    Points: 80\n",
    "\n",
    "\n",
    "    -----------------------------------\n",
    "    Question 1:\n",
    "    Points: 20\n",
    "    -----------------------------------\n",
    "    \n",
    "    -----------------------------------\n",
    "    Question 2:\n",
    "    Points: 20\n",
    "    -----------------------------------\n",
    "        \n",
    "    -----------------------------------\n",
    "    Question 3:\n",
    "    Points: 20\n",
    "    -----------------------------------\n",
    "  \n",
    "    -----------------------------------\n",
    "    Question 4:  Business question\n",
    "    Points: 20\n",
    "    -----------------------------------\n",
    "        Novelty: 10\n",
    "        Interestingness: 10\n",
    "    -----------------------------------\n",
    "    Come up with a business question and describe how Twitter data and a NoSQL database such as MongoDB call help you anser it.\n",
    "\n",
    "\n",
    "---------------------------------------------------------------------------\n",
    "**Slides (for 10 minutes of presentation): Story-telling**\n",
    "    Points: 20\n",
    "\n",
    "\n",
    "1. Motivation about the data collection, why the topic is interesting to you.\n",
    "    Points: 5 \n",
    "\n",
    "2. Communicating Results (figure/table)\n",
    "    Points: 10 \n",
    "\n",
    "3. Story telling (How all the parts (data, analysis, result) fit together as a story?)\n",
    "    Points: 5 \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "nteract": {
   "version": "0.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}